name: "OpenAI API Compatibility Layer"
description: "Add /v1/chat/completions endpoint for instant compatibility with 90% of AI tools"
version: "1.0"

steps:
  - step_type: "command"
    description: "Create OpenAI compatibility module"
    command: "touch"
    args: ["src/openai_compat.rs"]
    
  - step_type: "command" 
    description: "Add module to lib.rs"
    command: "bash"
    args: ["-c", "echo 'pub mod openai_compat;' >> src/lib.rs"]
    
  - step_type: "command"
    description: "Create basic OpenAI types and endpoint"
    command: "bash"
    args: ["-c", "cat > src/openai_compat.rs << 'EOF'
use serde::{Deserialize, Serialize};
use axum::{extract::State, Json, response::IntoResponse};
use std::sync::Arc;
use crate::{api::{ChatMessage, GenerateRequest}, AppState};

#[derive(Debug, Deserialize)]
pub struct ChatCompletionRequest {
    pub model: String,
    pub messages: Vec<ChatMessage>,
    #[serde(default)]
    pub stream: Option<bool>,
    #[serde(default)]
    pub temperature: Option<f32>,
    #[serde(default)]
    pub max_tokens: Option<usize>,
}

#[derive(Debug, Serialize)]
pub struct ChatCompletionResponse {
    pub id: String,
    pub object: String,
    pub created: u64,
    pub model: String,
    pub choices: Vec<Choice>,
}

#[derive(Debug, Serialize)]
pub struct Choice {
    pub index: usize,
    pub message: ChatMessage,
    pub finish_reason: Option<String>,
}

pub async fn chat_completions(
    State(state): State<Arc<AppState>>,
    Json(req): Json<ChatCompletionRequest>
) -> impl IntoResponse {
    // Convert OpenAI request to shimmy format
    let shimmy_req = GenerateRequest {
        model: req.model.clone(),
        prompt: None,
        messages: Some(req.messages),
        system: None,
        temperature: req.temperature,
        top_p: None,
        top_k: None,
        max_tokens: req.max_tokens,
        stream: req.stream,
    };
    
    // Use existing generate endpoint logic
    crate::api::generate(State(state), Json(shimmy_req)).await
}
EOF"]

  - step_type: "command"
    description: "Add route to server.rs"
    command: "sed"
    args: ["-i", "s|.route(\"/ws/generate\", get(api::ws_generate))|.route(\"/ws/generate\", get(api::ws_generate))\\n        .route(\"/v1/chat/completions\", post(crate::openai_compat::chat_completions))|", "src/server.rs"]

  - step_type: "command"
    description: "Test build"
    command: "cargo"
    args: ["build", "--features", "llama"]
