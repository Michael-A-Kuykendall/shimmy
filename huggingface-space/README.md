---
title: Shimmy - Universal LLM Shim
emoji: üîÑ
colorFrom: red
colorTo: blue
sdk: gradio
sdk_version: 4.44.0
app_file: app.py
pinned: false
license: apache-2.0
short_description: Stop converting your models. Start using them. Universal LLM serving for PEFT, GGUF, and beyond.
---

# Shimmy: Universal LLM Shim

**Run ANY model format through Ollama-compatible API**

Stop converting your models. Start using them.

Shimmy provides a single Ollama-compatible API for any model format - PEFT/LoRA, GGUF, and future formats.

## üéØ The Problem

- ‚ùå Ollama forces lossy GGUF conversion  
- ‚ùå No universal model serving solution exists
- ‚ùå Each format needs different tooling
- ‚ùå Converting models loses precision

## ‚ú® The Solution

Universal LLM shim with Ollama-compatible API for any model format.

## Features

- ‚úÖ **PEFT/LoRA Support**: Use your fine-tuned models directly
- ‚úÖ **GGUF Support**: Keep your quantized models for performance  
- ‚úÖ **Ollama API**: Drop-in replacement for existing workflows
- ‚úÖ **Zero Dependencies**: Single Rust binary, no Python needed
- ‚úÖ **Multi-Backend**: Automatic backend selection for optimal performance

Visit our GitHub repository for downloads and documentation.